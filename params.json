{"name":"Pml","tagline":"","body":"\r\n\r\n\r\n\r\n</head>\r\n\r\n<body>\r\n<h1>Practical Maching Learning Couse Project</h1>\r\n\r\n<h3>Loading the basic library</h3>\r\n\r\n<pre><code class=\"r\">library(caret)\r\n</code></pre>\r\n\r\n<pre><code>## Loading required package: lattice\r\n## Loading required package: ggplot2\r\n</code></pre>\r\n\r\n<pre><code>## Warning: couldn&#39;t connect to display &quot;:0&quot;\r\n</code></pre>\r\n\r\n<pre><code class=\"r\">library(randomForest)\r\n</code></pre>\r\n\r\n<pre><code>## randomForest 4.6-7\r\n## Type rfNews() to see new features/changes/bug fixes.\r\n</code></pre>\r\n\r\n<h3>Loading the orignal data form csv file</h3>\r\n\r\n<pre><code class=\"r\">trainRawData &lt;- read.csv(&quot;pml-training.csv&quot;, na.strings = c(&quot;NA&quot;, &quot;&quot;))\r\ntestRawData &lt;- read.csv(&quot;pml-testing.csv&quot;, na.strings = c(&quot;NA&quot;, &quot;&quot;))\r\n</code></pre>\r\n\r\n<h3>Cleanup the NA data in the original data</h3>\r\n\r\n<pre><code class=\"r\">NAs &lt;- apply(trainRawData, 2, function(x) {\r\n    sum(is.na(x))\r\n})\r\nvalidData &lt;- trainRawData[, which(NAs == 0)]\r\n</code></pre>\r\n\r\n<h3>Partition the &ldquo;clean&rdquo; data into training set and test set for cross validation</h3>\r\n\r\n<pre><code class=\"r\">trainIndex &lt;- createDataPartition(y = validData$classe, p = 0.2, list = FALSE)  # 3927 rows\r\ntrainData &lt;- validData[trainIndex, ]\r\ntestData &lt;- validData[-trainIndex, ]\r\n\r\nremoveIndex &lt;- grep(&quot;timestamp|X|user_name|new_window&quot;, names(trainData))\r\ntrainData &lt;- trainData[, -removeIndex]\r\n</code></pre>\r\n\r\n<h3>Train the model with the clean and selected training set by random forest</h3>\r\n\r\n<pre><code class=\"r\">modFit &lt;- train(trainData$classe ~ ., data = trainData, method = &quot;rf&quot;)\r\nmodFit\r\n</code></pre>\r\n\r\n<pre><code>## Random Forest \r\n## \r\n## 3927 samples\r\n##   53 predictors\r\n##    5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; \r\n## \r\n## No pre-processing\r\n## Resampling: Bootstrapped (25 reps) \r\n## \r\n## Summary of sample sizes: 3927, 3927, 3927, 3927, 3927, 3927, ... \r\n## \r\n## Resampling results across tuning parameters:\r\n## \r\n##   mtry  Accuracy  Kappa  Accuracy SD  Kappa SD\r\n##   2     1         1      0.004        0.005   \r\n##   30    1         1      0.005        0.006   \r\n##   50    1         1      0.006        0.008   \r\n## \r\n## Accuracy was used to select the optimal model using  the largest value.\r\n## The final value used for the model was mtry = 27.\r\n</code></pre>\r\n\r\n<h3>Using test set to calculate the sample error rate</h3>\r\n\r\n<pre><code class=\"r\">predictions = predict(modFit, testData)\r\naccuracy_true &lt;- sum(predictions == testData$classe)/length(predictions)\r\nsample_error = 1 - accuracy_true\r\ncat(&quot;Sample error rate: &quot;, sample_error * 100, &quot;%&quot;)\r\n</code></pre>\r\n\r\n<pre><code>## Sample error rate:  1.733 %\r\n</code></pre>\r\n\r\n<h3>Try to evaluate the sample error and the prediction result</h3>\r\n\r\n<pre><code class=\"r\">pred &lt;- predict(modFit, testRawData)\r\nprint(pred)\r\n</code></pre>\r\n\r\n<pre><code>##  [1] B A A A A E D B A A B C B A E E A B B B\r\n## Levels: A B C D E\r\n</code></pre>\r\n\r\n</body>\r\n\r\n</html>\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}